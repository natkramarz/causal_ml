{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [EconML](https://github.com/py-why/EconML)\n",
    "\n",
    "Biblioteka skoncentrowana na modelowaniu heterogenicznych efektów interwencji przy użyciu technik nauczania maszynowego. Jest wspierana przez firmę Micrososft. Jej zakres jest podobny do biblioteki CausalML. Biblioteka ta jest ściśle związana z biblioteką DoWhy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked_Q', 'Embarked_S', 'Sex_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['Age', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked'] + ['Pclass'] +  ['Survived'], how='any')\n",
    "df_cleaned = pd.get_dummies(df, columns=['Embarked', 'Sex'], drop_first=True)\n",
    "\n",
    "columns_to_check = ['Age', 'Sex_male', 'SibSp', 'Parch', 'Fare', 'Embarked_Q', 'Embarked_S']\n",
    "df_cleaned = df_cleaned.dropna(subset=columns_to_check, how='any')\n",
    "print(df_cleaned.columns)\n",
    "\n",
    "X = df_cleaned[['Age', 'Sex_male', 'SibSp', 'Parch', 'Fare', 'Embarked_Q', 'Embarked_S']]\n",
    "T = df_cleaned['Pclass']\n",
    "Y = df_cleaned['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<econml.dr._drlearner.DRLearner at 0x7f5234a36bb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from econml.dr import DRLearner\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "model_y = RandomForestRegressor()\n",
    "model_t = RandomForestClassifier()\n",
    "\n",
    "dr_learner = DRLearner(model_regression=model_y, model_propensity=model_t)\n",
    "\n",
    "dr_learner.fit(Y, T, X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown Categories: Empty DataFrame\n",
      "Columns: [Age, Sex_male, SibSp, Parch, Fare, Embarked_Q, Embarked_S]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unknown_categories = X[X.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "print(\"Unknown Categories:\", unknown_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories [0] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m treatment_effects \u001b[38;5;241m=\u001b[39m \u001b[43mdr_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# average treatment effect\u001b[39;00m\n\u001b[1;32m      4\u001b[0m ate \u001b[38;5;241m=\u001b[39m treatment_effects\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/wsi/venv/lib/python3.9/site-packages/econml/_cate_estimator.py:914\u001b[0m, in \u001b[0;36mTreatmentExpansionMixin.effect\u001b[0;34m(self, X, T0, T1)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meffect\u001b[39m(\u001b[38;5;28mself\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, T0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, T1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;66;03m# NOTE: don't explicitly expand treatments here, because it's done in the super call\u001b[39;00m\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/wsi/venv/lib/python3.9/site-packages/econml/_cate_estimator.py:600\u001b[0m, in \u001b[0;36mLinearCateEstimator.effect\u001b[0;34m(self, X, T0, T1)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meffect\u001b[39m(\u001b[38;5;28mself\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, T0, T1):\n\u001b[1;32m    576\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    Calculate the heterogeneous treatment effect :math:`\\\\tau(X, T0, T1)`.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m        singleton dimension will be collapsed (so this method will return a vector)\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 600\u001b[0m     X, T0, T1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_expand_treatments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;66;03m# TODO: what if input is sparse? - there's no equivalent to einsum,\u001b[39;00m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;66;03m#       but tensordot can't be applied to this problem because we don't sum over m\u001b[39;00m\n\u001b[1;32m    603\u001b[0m     eff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_marginal_effect(X)\n",
      "File \u001b[0;32m~/wsi/venv/lib/python3.9/site-packages/econml/_cate_estimator.py:871\u001b[0m, in \u001b[0;36mTreatmentExpansionMixin._expand_treatments\u001b[0;34m(self, X, transform, *Ts)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_treatment_featurizer:\n\u001b[1;32m    870\u001b[0m             T \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 871\u001b[0m         T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m     outTs\u001b[38;5;241m.\u001b[39mappend(T)\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (X,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(outTs)\n",
      "File \u001b[0;32m~/wsi/venv/lib/python3.9/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/wsi/venv/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:1023\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1022\u001b[0m }\n\u001b[0;32m-> 1023\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/wsi/venv/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:213\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    209\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[1;32m    212\u001b[0m     )\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories [0] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "# pomieszane typy zmiennych sprawdzic \n",
    "treatment_effects = dr_learner.effect(X)\n",
    "\n",
    "# average treatment effect\n",
    "ate = treatment_effects.mean()\n",
    "print(f\"Average Treatment Effect: {ate}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
